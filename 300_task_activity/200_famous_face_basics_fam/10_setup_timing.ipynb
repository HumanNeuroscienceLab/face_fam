{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates timing files for afni. It will make ones for:\n",
    "\n",
    "* faces (onsets)\n",
    "* famous (vs non-famous) faces (onsets for famous and non-famous)\n",
    "* repetition of the same video (ensure to scale...separate by famous/non-famous?)\n",
    "* repetition of the exemplar (ensure to scale)\n",
    "\n",
    "Let's do the first two first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import readline\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "r = robjects.r\n",
    "\n",
    "import rpy2.robjects.numpy2ri\n",
    "rpy2.robjects.numpy2ri.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub02\n",
      "/data1/famface01/command/misc/face_representations/300_task_activity/200_famous_face_basics_fam/timings/sub02\n",
      "sub03\n",
      "/data1/famface01/command/misc/face_representations/300_task_activity/200_famous_face_basics_fam/timings/sub03\n",
      "sub04\n",
      "/data1/famface01/command/misc/face_representations/300_task_activity/200_famous_face_basics_fam/timings/sub04\n",
      "sub05\n",
      "/data1/famface01/command/misc/face_representations/300_task_activity/200_famous_face_basics_fam/timings/sub05\n",
      "sub06\n",
      "/data1/famface01/command/misc/face_representations/300_task_activity/200_famous_face_basics_fam/timings/sub06\n"
     ]
    }
   ],
   "source": [
    "# Skip the first subject...for now\n",
    "for si in range(1,6):\n",
    "    subj = \"sub%02i\" % (si+1)\n",
    "    print(subj)\n",
    "    \n",
    "    # Load the R data\n",
    "    infile = \"/data1/famface01/analysis/encoding/ShapeAnalysis/data/fam_roi_n_more_%s.rda\" % subj\n",
    "    r.load(infile)\n",
    "    \n",
    "    # Variables\n",
    "    onsets     = np.array(r.dat.rx2('basics').rx2('timing').rx2('onset'))\n",
    "    questions  = np.array(r['as.character'](r.dat.rx2('basics').rx2('timing').rx2('question')))\n",
    "    vids       = np.array(r['as.character'](r.dat.rx2('basics').rx2('timing').rx2('video')))\n",
    "    vidlevs    = np.array(r.dat.rx2('basics').rx2('timing').rx2('video').levels)\n",
    "    fams       = np.array(r.dat.rx2('basics').rx2('timing').rx2('fam'))\n",
    "    runs       = np.array(r.dat.rx2('basics').rx2('timing').rx2('run'))\n",
    "    uruns      = np.unique(runs)\n",
    "\n",
    "    # Get repeated vids\n",
    "    vid_reps = np.zeros(len(vids))\n",
    "    for vname in vidlevs:\n",
    "        vid_reps[vids == vname] = [1,2]\n",
    "    \n",
    "    # Person repeats\n",
    "    import re\n",
    "    persons = np.array([ re.sub(\"_num[0-9]{2}\", \"\", vname) for vname in vids ])\n",
    "    upersons= np.unique(persons)\n",
    "    person_reps = np.zeros(len(persons))\n",
    "    for pname in upersons:\n",
    "        person_reps[persons == pname] = range(1,13)\n",
    "\n",
    "    \n",
    "    ###\n",
    "    # FACE ACTIVITY\n",
    "    ###\n",
    "\n",
    "    nruns = uruns.shape[0]\n",
    "    afni_facemat = []\n",
    "\n",
    "    for ri in range(nruns):\n",
    "        run_inds = runs == uruns[ri]\n",
    "        n = np.sum(run_inds)\n",
    "\n",
    "        ovec = onsets[run_inds].astype('float32').round(4)\n",
    "        row = [ '%.2f' % ovec[i] for i in range(n) ]\n",
    "        row = \" \".join(row)\n",
    "\n",
    "        afni_facemat.append(row)\n",
    "\n",
    "    afni_facemat = np.array(afni_facemat)\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # QUESTIONS\n",
    "    ###\n",
    "\n",
    "    q_regressor = (questions != 'none') * 1\n",
    "\n",
    "    afni_qmat = []\n",
    "    nruns = uruns.shape[0]\n",
    "    for ri in range(nruns):\n",
    "        run_inds = runs == uruns[ri]\n",
    "        n = np.sum(run_inds)\n",
    "\n",
    "        qvec = q_regressor[run_inds]\n",
    "        ovec = onsets[run_inds].astype('float32').round(4)\n",
    "        row  = np.array([ '%.2f' % ovec[i] for i,touse in enumerate(qvec) if touse == 1 ])\n",
    "        if len(row) == 0:\n",
    "            row = '*'\n",
    "        else:\n",
    "            row = \" \".join(row)\n",
    "\n",
    "        afni_qmat.append(row)\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # FAMOUS/NON-FAMOUS FACE ACTIVITY\n",
    "    ###\n",
    "\n",
    "    nruns = uruns.shape[0]\n",
    "\n",
    "    # Famous\n",
    "    afni_fammat = []\n",
    "    for ri in range(nruns):\n",
    "        run_inds = (runs == uruns[ri]) & (fams == \"yes\")\n",
    "        n = np.sum(run_inds)\n",
    "        ovec = onsets[run_inds].astype('float32').round(4)\n",
    "        row = [ '%.2f' % ovec[i] for i in range(n) ]\n",
    "        row = \" \".join(row)\n",
    "        afni_fammat.append(row)\n",
    "    afni_fammat = np.array(afni_fammat)\n",
    "\n",
    "    # NonFamous\n",
    "    afni_nonfammat = []\n",
    "    for ri in range(nruns):\n",
    "        run_inds = (runs == uruns[ri]) & (fams == \"no\")\n",
    "        n = np.sum(run_inds)\n",
    "        ovec = onsets[run_inds].astype('float32').round(4)\n",
    "        row = [ '%.2f' % ovec[i] for i in range(n) ]\n",
    "        row = \" \".join(row)\n",
    "        afni_nonfammat.append(row)\n",
    "    afni_nonfammat = np.array(afni_nonfammat)\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # MOTION\n",
    "    ###\n",
    "\n",
    "    funcdir = \"/data1/famface01/analysis/preprocessed/%s/func\" % subj\n",
    "    df_paths = pd.read_table(\"%s/df_paths.txt\" % funcdir, sep=\" \")\n",
    "\n",
    "    inds = df_paths.inindex[df_paths.name == 'fam_vids']\n",
    "    motion_fpaths = [ \"%s/mc/func_run%02i_dfile.1D\" % (funcdir, ind) for ind in inds ]\n",
    "\n",
    "    from sklearn.preprocessing import scale\n",
    "    motion_mats = []\n",
    "    for fpath in motion_fpaths:\n",
    "        x = np.loadtxt(fpath)\n",
    "        x = scale(x, with_std=False, with_mean=True)\n",
    "        motion_mats.append(x)\n",
    "    motion_mat = np.vstack(motion_mats)\n",
    "    \n",
    "    \n",
    "    ###\n",
    "    # SAVE\n",
    "    ###\n",
    "\n",
    "    base = \"/data1/famface01/command/misc/face_representations\"\n",
    "    outbase = \"%s/300_task_activity/200_famous_face_basics_fam/timings\" % base\n",
    "    outdir = \"%s/%s\" % (outbase, subj)\n",
    "    print outdir\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "\n",
    "    # Just faces\n",
    "    ofname = '%s/stim_faces.txt' % outdir\n",
    "    np.savetxt(ofname, afni_facemat, fmt='%s')\n",
    "\n",
    "    # Famous\n",
    "    ofname = '%s/stim_famous.txt' % outdir\n",
    "    np.savetxt(ofname, afni_fammat, fmt='%s')\n",
    "    ofname = '%s/stim_nonfamous.txt' % outdir\n",
    "    np.savetxt(ofname, afni_nonfammat, fmt='%s')\n",
    "\n",
    "    # Questions\n",
    "    ofname = '%s/stim_questions.txt' % outdir\n",
    "    np.savetxt(ofname, afni_qmat, fmt='%s')\n",
    "\n",
    "    # MOTION\n",
    "    ofname = '%s/motion.1D' % outdir\n",
    "    np.savetxt(ofname, motion_mat, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/famface01/analysis/encoding/ShapeAnalysis/data/fam_roi_n_more_sub03.rda\n",
      "[1] \"run\"         \"onset\"       \"local.onset\" \"duration\"    \"question\"   \n",
      "[6] \"video\"       \"fam\"        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "subj = \"sub03\"\n",
    "\n",
    "# Load the R data\n",
    "infile = \"/data1/famface01/analysis/encoding/ShapeAnalysis/data/fam_roi_n_more_%s.rda\" % subj\n",
    "print(infile)\n",
    "r.load(infile)\n",
    "\n",
    "print(r.dat.rx2('basics').rx2('timing').names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        age  attractive      gender intelligent        none trustworthy \n",
      "          8           8          16           8         720           8 \n",
      "\n",
      "\n",
      " 1  2  3  4  5  6  7  8 \n",
      "96 96 96 96 96 96 96 96 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "onsets     = np.array(r.dat.rx2('basics').rx2('timing').rx2('onset'))\n",
    "questions  = np.array(r['as.character'](r.dat.rx2('basics').rx2('timing').rx2('question')))\n",
    "vids       = np.array(r['as.character'](r.dat.rx2('basics').rx2('timing').rx2('video')))\n",
    "vidlevs    = np.array(r.dat.rx2('basics').rx2('timing').rx2('video').levels)\n",
    "fams       = np.array(r.dat.rx2('basics').rx2('timing').rx2('fam'))\n",
    "runs       = np.array(r.dat.rx2('basics').rx2('timing').rx2('run'))\n",
    "uruns      = np.unique(runs)\n",
    "\n",
    "print(r.table(questions))\n",
    "print(r.table(runs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we want to get if the same video repeated or not\n",
    "vid_reps = np.zeros(len(vids))\n",
    "for vname in vidlevs:\n",
    "    vid_reps[vids == vname] = [1,2]\n",
    "vid_reps[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        2.,  1.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,\n",
       "        1.,  1.,  2.,  2.,  2.,  3.,  1.,  2.,  2.,  2.,  1.,  2.,  2.,\n",
       "        1.,  1.,  2.,  2.,  1.,  1.,  1.,  2.,  3.,  2.,  3.,  2.,  1.,\n",
       "        3.,  2.,  2.,  3.,  2.,  3.,  3.,  1.,  3.,  3.,  3.,  3.,  2.,\n",
       "        2.,  2.,  3.,  3.,  2.,  2.,  2.,  3.,  2.,  3.,  1.,  3.,  2.,\n",
       "        3.,  3.,  2.,  3.,  3.,  3.,  3.,  3.,  3.,  3.,  2.,  3.,  3.,\n",
       "        3.,  3.,  3.,  3.,  3.,  4.,  4.,  4.,  4.,  4.,  5.,  4.,  4.,\n",
       "        4.,  4.,  4.,  4.,  4.,  5.,  4.,  4.,  4.,  5.,  4.,  4.,  5.,\n",
       "        4.,  5.,  5.,  4.,  5.,  4.,  4.,  5.,  4.,  5.,  5.,  4.,  6.,\n",
       "        4.,  4.,  5.,  5.,  4.,  4.,  5.,  4.,  5.,  5.,  4.,  4.,  5.,\n",
       "        5.,  5.,  5.,  4.,  6.,  6.,  5.,  5.,  6.,  6.,  5.,  5.,  6.,\n",
       "        6.,  6.,  6.,  5.,  6.,  5.,  6.,  6.,  6.,  6.,  6.,  5.,  5.,\n",
       "        4.,  6.,  5.,  6.,  5.,  6.,  5.,  6.,  6.,  6.,  5.,  6.,  6.,\n",
       "        6.,  6.,  5.,  6.,  6.,  6.,  6.,  6.,  6.,  6.,  7.,  7.,  7.,\n",
       "        7.,  7.,  7.,  7.,  7.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now we want when the same person's video repeats\n",
    "import re\n",
    "\n",
    "persons = np.array([ re.sub(\"_num[0-9]{2}\", \"\", vname) for vname in vids ])\n",
    "upersons= np.unique(persons)\n",
    "\n",
    "person_reps = np.zeros(len(persons))\n",
    "for pname in upersons:\n",
    "    person_reps[persons == pname] = range(1,13)\n",
    "person_reps[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ '0.00 2.00 4.00 8.00 10.00 12.00 14.00 16.00 18.00 22.00 26.00 28.00 30.00 34.00 44.00 48.00 54.00 56.00 58.00 60.00 64.00 66.00 70.00 72.00 74.00 78.00 80.00 82.00 84.00 86.00 88.00 90.00 94.00 96.00 98.00 104.00 106.00 108.00 112.00 116.00 118.00 122.00 124.00 126.00 128.00 130.00 134.00 136.00 140.00 142.00 144.00 146.00 150.00 152.00 154.00 156.00 160.00 162.00 168.00 170.00 176.00 178.00 180.00 184.00 186.00 188.00 190.00 192.00 196.00 200.00 204.00 206.00 208.00 210.00 218.00 222.00 224.00 228.00 232.00 234.00 236.00 240.00 242.00 246.00 248.00 250.00 252.00 254.00 258.00 264.00 266.00 268.00 272.00 274.00 276.00 278.00',\n",
       "       '286.00 288.00 290.00 292.00 294.00 296.00 300.00 302.00 304.00 306.00 308.00 310.00 316.00 322.00 324.00 326.00 328.00 330.00 334.00 336.00 338.00 340.00 346.00 348.00 352.00 354.00 358.00 360.00 362.00 366.00 368.00 370.00 374.00 378.00 380.00 384.00 386.00 388.00 394.00 398.00 400.00 402.00 406.00 408.00 410.00 414.00 416.00 418.00 424.00 426.00 428.00 430.00 432.00 436.00 438.00 440.00 442.00 448.00 454.00 456.00 460.00 462.00 464.00 468.00 470.00 472.00 476.00 478.00 484.00 486.00 490.00 494.00 496.00 502.00 504.00 508.00 512.00 514.00 518.00 520.00 522.00 526.00 528.00 530.00 532.00 534.00 536.00 540.00 542.00 550.00 552.00 556.00 558.00 560.00 562.00 564.00'], \n",
       "      dtype='|S767')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# FACE ACTIVITY\n",
    "###\n",
    "\n",
    "nruns = uruns.shape[0]\n",
    "afni_facemat = []\n",
    "\n",
    "for ri in range(nruns):\n",
    "    run_inds = runs == uruns[ri]\n",
    "    n = np.sum(run_inds)\n",
    "    \n",
    "    ovec = onsets[run_inds].astype('float32').round(4)\n",
    "    row = [ '%.2f' % ovec[i] for i in range(n) ]\n",
    "    row = \" \".join(row)\n",
    "\n",
    "    afni_facemat.append(row)\n",
    "\n",
    "afni_facemat = np.array(afni_facemat)\n",
    "afni_facemat[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  0   1 \n",
      "720  48 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['34.00 48.00 98.00 162.00 210.00 258.00',\n",
       " '310.00 340.00 388.00 448.00 496.00 542.00']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###\n",
    "# QUESTIONS\n",
    "###\n",
    "\n",
    "q_regressor = (questions != 'none') * 1\n",
    "print(r.table(q_regressor))\n",
    "\n",
    "## note: this will need to be saved separately\n",
    "\n",
    "afni_qmat = []\n",
    "nruns = uruns.shape[0]\n",
    "for ri in range(nruns):\n",
    "    run_inds = runs == uruns[ri]\n",
    "    n = np.sum(run_inds)\n",
    "\n",
    "    qvec = q_regressor[run_inds]\n",
    "    ovec = onsets[run_inds].astype('float32').round(4)\n",
    "    row  = np.array([ '%.2f' % ovec[i] for i,touse in enumerate(qvec) if touse == 1 ])\n",
    "    if len(row) == 0:\n",
    "        row = '*'\n",
    "    else:\n",
    "        row = \" \".join(row)\n",
    "    \n",
    "    afni_qmat.append(row)\n",
    "\n",
    "afni_qmat[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ '0.00 2.00 4.00 8.00 10.00 12.00 14.00 16.00 18.00 26.00 28.00 30.00 34.00 44.00 48.00 54.00 56.00 58.00 60.00 66.00 72.00 74.00 78.00 80.00 82.00 84.00 86.00 88.00 90.00 94.00 96.00 98.00 104.00 106.00 108.00 112.00 116.00 118.00 124.00 126.00 128.00 130.00 134.00 136.00 140.00 142.00 144.00 146.00 150.00 152.00 154.00 156.00 160.00 162.00 168.00 176.00 178.00 184.00 186.00 188.00 190.00 192.00 196.00 200.00 204.00 206.00 208.00 210.00 218.00 224.00 228.00 234.00 240.00 242.00 246.00 248.00 250.00 254.00 264.00 266.00 268.00 272.00 276.00 278.00'\n",
      " '286.00 288.00 290.00 292.00 294.00 296.00 300.00 302.00 304.00 306.00 308.00 310.00 316.00 322.00 324.00 328.00 330.00 334.00 336.00 338.00 340.00 346.00 352.00 354.00 362.00 366.00 368.00 370.00 374.00 378.00 380.00 384.00 386.00 388.00 398.00 400.00 402.00 406.00 410.00 414.00 416.00 418.00 424.00 428.00 430.00 432.00 436.00 438.00 440.00 442.00 448.00 454.00 456.00 462.00 464.00 468.00 470.00 472.00 476.00 478.00 486.00 490.00 496.00 502.00 504.00 508.00 512.00 514.00 518.00 520.00 522.00 526.00 528.00 530.00 532.00 534.00 536.00 540.00 542.00 550.00 552.00 556.00 562.00 564.00']\n",
      "[ '22.00 64.00 70.00 122.00 170.00 180.00 222.00 232.00 236.00 252.00 258.00 274.00'\n",
      " '326.00 348.00 358.00 360.00 394.00 408.00 426.00 460.00 484.00 494.00 558.00 560.00']\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# FAMOUS/NON-FAMOUS FACE ACTIVITY\n",
    "###\n",
    "\n",
    "nruns = uruns.shape[0]\n",
    "\n",
    "# Famous\n",
    "afni_fammat = []\n",
    "for ri in range(nruns):\n",
    "    run_inds = (runs == uruns[ri]) & (fams == \"yes\")\n",
    "    n = np.sum(run_inds)\n",
    "    ovec = onsets[run_inds].astype('float32').round(4)\n",
    "    row = [ '%.2f' % ovec[i] for i in range(n) ]\n",
    "    row = \" \".join(row)\n",
    "    afni_fammat.append(row)\n",
    "afni_fammat = np.array(afni_fammat)\n",
    "\n",
    "# NonFamous\n",
    "afni_nonfammat = []\n",
    "for ri in range(nruns):\n",
    "    run_inds = (runs == uruns[ri]) & (fams == \"no\")\n",
    "    n = np.sum(run_inds)\n",
    "    ovec = onsets[run_inds].astype('float32').round(4)\n",
    "    row = [ '%.2f' % ovec[i] for i in range(n) ]\n",
    "    row = \" \".join(row)\n",
    "    afni_nonfammat.append(row)\n",
    "afni_nonfammat = np.array(afni_nonfammat)\n",
    "\n",
    "print afni_fammat[:2]\n",
    "print afni_nonfammat[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "# MOTION\n",
    "###\n",
    "\n",
    "funcdir = \"/data1/famface01/analysis/preprocessed/%s/func\" % subj\n",
    "df_paths = pd.read_table(\"%s/df_paths.txt\" % funcdir, sep=\" \")\n",
    "\n",
    "inds = df_paths.inindex[df_paths.name == 'fam_vids']\n",
    "motion_fpaths = [ \"%s/mc/func_run%02i_dfile.1D\" % (funcdir, ind) for ind in inds ]\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "motion_mats = []\n",
    "for fpath in motion_fpaths:\n",
    "    x = np.loadtxt(fpath)\n",
    "    x = scale(x, with_std=False, with_mean=True)\n",
    "    motion_mats.append(x)\n",
    "motion_mat = np.vstack(motion_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19022832, -0.14823951, -0.12488741,  0.06031958, -0.13491189,\n",
       "        -0.02307552],\n",
       "       [-0.17122832, -0.08213951, -0.14778741,  0.04431958, -0.12501189,\n",
       "         0.06402448],\n",
       "       [-0.15632832, -0.06123951, -0.10048741, -0.00618042, -0.11831189,\n",
       "         0.05532448],\n",
       "       ..., \n",
       "       [ 0.00352902,  0.0941958 ,  0.03237867, -0.11997308, -0.01660839,\n",
       "         0.03874336],\n",
       "       [ 0.00622902,  0.1072958 ,  0.02277867, -0.14177308, -0.00790839,\n",
       "         0.03494336],\n",
       "       [ 0.00742902,  0.0340958 ,  0.01687867, -0.02637308, -0.00930839,\n",
       "        -0.05065664]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/famface01/command/misc/face_representations/300_task_activity/200_famous_face_basics_fam/timings/sub03\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# SAVE\n",
    "###\n",
    "\n",
    "base = \"/data1/famface01/command/misc/face_representations\"\n",
    "outbase = \"%s/300_task_activity/200_famous_face_basics_fam/timings\" % base\n",
    "outdir = \"%s/%s\" % (outbase, subj)\n",
    "print outdir\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "# Just faces\n",
    "ofname = '%s/stim_faces.txt' % outdir\n",
    "np.savetxt(ofname, afni_facemat, fmt='%s')\n",
    "\n",
    "# Famous\n",
    "ofname = '%s/stim_famous.txt' % outdir\n",
    "np.savetxt(ofname, afni_fammat, fmt='%s')\n",
    "ofname = '%s/stim_nonfamous.txt' % outdir\n",
    "np.savetxt(ofname, afni_nonfammat, fmt='%s')\n",
    "\n",
    "# Questions\n",
    "ofname = '%s/stim_questions.txt' % outdir\n",
    "np.savetxt(ofname, afni_qmat, fmt='%s')\n",
    "\n",
    "# MOTION\n",
    "ofname = '%s/motion.1D' % outdir\n",
    "np.savetxt(ofname, motion_mat, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
